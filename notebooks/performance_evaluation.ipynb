{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# HIRM Performance Evaluation\n",
                "\n",
                "This notebook runs the `baseline_benchmark` experiment to evaluate the model's performance (PnL) and compares it against baselines (ERM, IRM, GroupDRO, V-REx, Risk Parity)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup Environment\n",
                "import os\n",
                "\n",
                "# Ensure we start from the base directory in Colab\n",
                "if os.path.exists(\"/content\"):\n",
                "    %cd /content\n",
                "\n",
                "REPO_NAME = \"hirm-research\"\n",
                "REPO_URL = \"https://github.com/raei-2748/hirm-research.git\"\n",
                "\n",
                "if os.path.exists(REPO_NAME):\n",
                "    print(f\"Updating existing repository in {REPO_NAME}...\")\n",
                "    %cd {REPO_NAME}\n",
                "    !git pull\n",
                "else:\n",
                "    print(f\"Cloning repository to {REPO_NAME}...\")\n",
                "    !git clone {REPO_URL} {REPO_NAME}\n",
                "    %cd {REPO_NAME}\n",
                "\n",
                "print(f\"Current working directory: {os.getcwd()}\")\n",
                "%pip install -q -r requirements-colab.txt\n",
                "%pip install -q -e ."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run Baseline Benchmark\n",
                "# This runs multiple methods on synthetic and real datasets.\n",
                "# It may take 30-60 minutes depending on the hardware.\n",
                "!python scripts/run_grid.py --config configs/experiments/baseline_benchmark.yaml --device cuda"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summarize Results\n",
                "!python scripts/summarize_baseline_results.py --config configs/experiments/baseline_benchmark.yaml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display Results\n",
                "import pandas as pd\n",
                "import glob\n",
                "\n",
                "summary_files = glob.glob(\"results/baseline_benchmark/summary/*_summary.csv\")\n",
                "for f in summary_files:\n",
                "    print(f\"\\n=== {os.path.basename(f)} ===\")\n",
                "    df = pd.read_csv(f)\n",
                "    display(df)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}